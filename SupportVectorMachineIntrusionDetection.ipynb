{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeff-Rudolph/anomaly-based-intrusion-detection/blob/main/SupportVectorMachineIntrusionDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzCVOaZtj9sD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import scipy\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import sklearn.ensemble as ske\n",
        "import pandas\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack\n",
        "from sklearn import svm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWrgghhgtDuV"
      },
      "outputs": [],
      "source": [
        "file_size = int(input(\"Would you like to use 10% data file or full file?(0 - %, 1 - Full):\"))\n",
        "if(file_size == 0):\n",
        "  pdata = pandas.read_csv('/content/drive/My Drive/data/kddcup10pct.txt',header=None)\n",
        "if(file_size == 1):\n",
        "  pdata = pandas.read_csv('/content/drive/My Drive/data/kddcup_data_corrected.txt',header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oadVLaxlGNvB"
      },
      "outputs": [],
      "source": [
        "feature_names_str = '''duration: continuous.\n",
        "protocol_type: symbolic.\n",
        "service: symbolic.\n",
        "flag: symbolic.\n",
        "src_bytes: continuous.\n",
        "dst_bytes: continuous.\n",
        "land: symbolic.\n",
        "wrong_fragment: continuous.\n",
        "urgent: continuous.\n",
        "hot: continuous.\n",
        "num_failed_logins: continuous.\n",
        "logged_in: symbolic.\n",
        "num_compromised: continuous.\n",
        "root_shell: continuous.\n",
        "su_attempted: continuous.\n",
        "num_root: continuous.\n",
        "num_file_creations: continuous.\n",
        "num_shells: continuous.\n",
        "num_access_files: continuous.\n",
        "num_outbound_cmds: continuous.\n",
        "is_host_login: symbolic.\n",
        "is_guest_login: symbolic.\n",
        "count: continuous.\n",
        "srv_count: continuous.\n",
        "serror_rate: continuous.\n",
        "srv_serror_rate: continuous.\n",
        "rerror_rate: continuous.\n",
        "srv_rerror_rate: continuous.\n",
        "same_srv_rate: continuous.\n",
        "diff_srv_rate: continuous.\n",
        "srv_diff_host_rate: continuous.\n",
        "dst_host_count: continuous.\n",
        "dst_host_srv_count: continuous.\n",
        "dst_host_same_srv_rate: continuous.\n",
        "dst_host_diff_srv_rate: continuous.\n",
        "dst_host_same_src_port_rate: continuous.\n",
        "dst_host_srv_diff_host_rate: continuous.\n",
        "dst_host_serror_rate: continuous.\n",
        "dst_host_srv_serror_rate: continuous.\n",
        "dst_host_rerror_rate: continuous.\n",
        "dst_host_srv_rerror_rate: continuous.'''\n",
        "\n",
        "temp = feature_names_str.split('.')\n",
        "feature_names = []\n",
        "\n",
        "\n",
        "for x in temp:\n",
        "  x = x.replace(\"\\n\",\"\")\n",
        "  x = x.replace(\": continuous\",\"\")\n",
        "  x = x.replace(\": symbolic\",\"\")\n",
        "  feature_names.append(x)\n",
        "\n",
        "feature_names.pop() #removes unnecessary empty string element at end of list\n",
        "feature_names.append('event') \n",
        "\n",
        "pdata.columns = feature_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspecting initial dataset\n",
        "print(pdata.shape)\n",
        "print(pdata['event'].value_counts()/len(pdata)*100)"
      ],
      "metadata": {
        "id": "KsbYF2fXylvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO1crW84JEwV"
      },
      "outputs": [],
      "source": [
        "pdata.drop_duplicates(keep='first', inplace = True) \n",
        "#removes duplicates if inplace=true \n",
        "#arg subset=false(default) this way things will only be removed if\n",
        "#100% match including event"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LN3U9FXKJIou"
      },
      "outputs": [],
      "source": [
        "#checking new size after removing dupes\n",
        "print(pdata.shape)\n",
        "print(pdata['event'].value_counts()/len(pdata)*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdzzGk7OT_iP"
      },
      "outputs": [],
      "source": [
        "#pdata.var(axis=0,numeric_only=True) \n",
        "#num outbound commands variance is 0 so we can drop this col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWqYWT4WhLu9"
      },
      "outputs": [],
      "source": [
        "dimensionality = int(input(\"Run the model with low or high dimensions?(0-low, 1-high):\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0mGcfzCzAnC"
      },
      "outputs": [],
      "source": [
        "if(dimensionality == 0):\n",
        "  pdata['protocol_type'] = pandas.factorize(pdata['protocol_type'])[0]\n",
        "  pdata['protocol_type'] = pdata['protocol_type'] - 1\n",
        "\n",
        "\n",
        "  pdata['service'] = pandas.factorize(pdata['service'])[0]\n",
        "  if(file_size == 0):\n",
        "    pdata['service'] = pdata['service'] - 33\n",
        "  if(file_size == 1):\n",
        "    pdata['service'] = pdata['service'] - 35\n",
        "\n",
        "  pdata['flag'] = pandas.factorize(pdata['flag'])[0]\n",
        "  pdata['flag'] = pdata['flag'] - 5\n",
        "\n",
        "#dummy variable text to int conversion for these categorical inputs to avoid\n",
        "#curse of dimensionality problems caused by OH encode need to make sure these \n",
        "#dont get normalized.\n",
        "#subtractions are to balance numbers around 0 \n",
        "#(10% and full have diff numbers for service tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nue3MD9g0C_p"
      },
      "outputs": [],
      "source": [
        "x_data = pdata.drop(['event'], axis=1)\n",
        "\n",
        "y_data = pdata['event'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vq4Xzuiy6K4k"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for i in range(len(y_data)):\n",
        "  if(y_data[i]=='normal.'):\n",
        "    count = count + 1\n",
        "balance = len(y_data)-count\n",
        "print(\"Number of normals:\",count)\n",
        "print(\"Number of data points:\",len(y_data))\n",
        "print(\"percent normal:\",count/(len(y_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiR8oGcbxM_O"
      },
      "outputs": [],
      "source": [
        "\n",
        "classification = int(input(\"Would you like to run with binary or multiclass Y values?(0 - binary, 1 - multi):\"))\n",
        "if(classification == 0):\n",
        "  for i in range(len(y_data)):\n",
        "    if y_data[i] in ['normal.']:\n",
        "      y_data[i] = 'normal'\n",
        "    else:\n",
        "      y_data[i] = 'hack' #converting to binary problem\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF4Qfxib0CPg"
      },
      "outputs": [],
      "source": [
        "x_data = x_data.drop(['num_outbound_cmds'],axis=1)\n",
        "#dropped for 0 variance in entire file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBluSPFWa0hZ"
      },
      "outputs": [],
      "source": [
        "x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(x_data,y_data,test_size=0.3) \n",
        "#randomly shuffles then splits data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ErAsasLY2yK"
      },
      "outputs": [],
      "source": [
        "if(dimensionality == 1):\n",
        "  protocol_cat = list(x_train['protocol_type'].values) #pull entire col into list\n",
        "  protocol_cat = list(set(protocol_cat)) \n",
        "  #turn list into mathematical set to remove duplicates\n",
        "\n",
        "\n",
        "  prot_OH_encoder = CountVectorizer(vocabulary=protocol_cat, binary=True) \n",
        "  #only 0 or 1 in sparse matrix\n",
        "  protocol_train = prot_OH_encoder.fit_transform(x_train['protocol_type'].values)\n",
        "  protocol_test = prot_OH_encoder.transform(x_test['protocol_type'].values)\n",
        "\n",
        "\n",
        "  service_cat = list(x_train['service'].values) #do same for service\n",
        "  service_cat = list(set(service_cat))\n",
        "\n",
        "\n",
        "  serv_OH_encoder = CountVectorizer(vocabulary=service_cat, binary=True,lowercase=False)\n",
        "  service_train = serv_OH_encoder.fit_transform(x_train['service'].values)\n",
        "\n",
        "  service_test = serv_OH_encoder.transform(x_test['service'].values)\n",
        "\n",
        "\n",
        "  flag_cat = list(x_train['flag'].values)#same for flag\n",
        "  flag_cat = list(set(flag_cat))\n",
        "\n",
        "\n",
        "  flag_OH_encoder = CountVectorizer(vocabulary=flag_cat, binary=True,lowercase=False)\n",
        "  flag_train = flag_OH_encoder.fit_transform(x_train['flag'].values)\n",
        "\n",
        "  flag_test = flag_OH_encoder.transform(x_test['flag'].values)\n",
        "\n",
        "  \n",
        "  x_train = x_train.drop(labels=['protocol_type','flag','service'],axis='columns')\n",
        "  x_test = x_test.drop(labels=['protocol_type','flag','service'],axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4IUPVHL9UwD"
      },
      "outputs": [],
      "source": [
        "x_normalizer = StandardScaler()\n",
        "\n",
        "x_train_norm = x_train\n",
        "x_test_norm = x_test\n",
        "\n",
        "continous_list = ['duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'num_compromised',\n",
        "                  'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'count',\n",
        "                  'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
        "                  'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate',\n",
        "                  'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
        "                  'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']\n",
        "#only apply Z score (StandardScaler) to numerical continous cols\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x_train_norm[continous_list] = x_normalizer.fit_transform(x_train[continous_list])\n",
        "x_test_norm[continous_list] = x_normalizer.transform(x_test[continous_list])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdDvpFbW92o1"
      },
      "outputs": [],
      "source": [
        "if(dimensionality == 1 ):\n",
        "  x_train_norm = hstack((x_train_norm,flag_train,service_train,protocol_train))\n",
        "  x_test_norm = hstack((x_test_norm,flag_test,service_test,protocol_test))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuRnqoG0TI4P"
      },
      "outputs": [],
      "source": [
        "###########################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uO5LdOF8X22e"
      },
      "outputs": [],
      "source": [
        "classifier = svm.SVC(decision_function_shape='ovo')\n",
        "# Train the model using the training sets\n",
        "classifier.fit(x_train_norm, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwNhj7-LZ2T_"
      },
      "outputs": [],
      "source": [
        "y_pred = classifier.predict(x_test_norm)\n",
        "#predict outcomes from testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWSubo3Sj7AP"
      },
      "outputs": [],
      "source": [
        "#due to the way this dataset was constructed the Recall the only valid metric:\n",
        "#“Trivial detection using the TTL aside, we found that it was still useful to \n",
        "# evaluate the true positive performance of a network IDS; however, any false \n",
        "# positive results were meaningless” (Brugger, 2007)\n",
        "\n",
        "print(sklearn.metrics.recall_score(y_test,y_pred,average='macro'))\n",
        "#the above line takes a simple average of the recall score for each class except\n",
        "#the normal class. The formula for recall is TP/TP+FN to avoid div by 0 this \n",
        "#method has built in measures. If all cases are properly identified then it \n",
        "#becomes TP/TP+0 = 1, if the event is not in the sample then recall is set to 0\n",
        "#The Data's imbalance will cause 0's to appear and drive down the macro average\n",
        "#In the case of SVM I could not seperate the normal case from the macro average.\n",
        "#To calculate you can remove the [11] \n",
        "#(this is always the  index of normal event tag in multiclass)\n",
        "#entry from the list produced in the output\n",
        "#below in the multiclass case and calculate your own average. \n",
        "\n",
        "\n",
        "#print(sklearn.metrics.accuracy_score(y_test,y_pred,normalize=False)) \n",
        "#raw number of correct predictions\n",
        "#print(len(y_test))\n",
        "#total number of events "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "petm35GhdWPl"
      },
      "outputs": [],
      "source": [
        "sklearn.metrics.recall_score(y_test,y_pred,average=None,zero_division=0)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SupportVectorMachineIntrusionDetection.ipynb",
      "provenance": [],
      "mount_file_id": "19-qSdUSiduwpXUVITVGLd5nL1itiBZ9d",
      "authorship_tag": "ABX9TyPSEyiF3YBeJJ4elG9fUtyb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}